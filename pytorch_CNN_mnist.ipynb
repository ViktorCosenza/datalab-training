{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Loading\n",
    "train = pd.read_csv('../mnist/mnist_train.csv')\n",
    "test = pd.read_csv('../mnist/mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation Set\n",
    "\n",
    "#Validation contains 100 Samples\n",
    "df_train = np.array(train)\n",
    "df_validation = df_train[:100, :]\n",
    "\n",
    "#Remove Samples from train set\n",
    "df_train = df_train[100:, :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 5989\n"
     ]
    }
   ],
   "source": [
    "#Data Processincg\n",
    "test_fraction = 10\n",
    "n_samples = int(df_train.shape[0]/sample_fraction)\n",
    "df_train = df_train[:n_samples, :]\n",
    "\n",
    "# Create x_train, y_train with adequate sizes\n",
    "x_train = df_train[:, 1:] / 255\n",
    "x_train = np.reshape(x_train, (n_samples ,28, 28))\n",
    "y_train = df_train[:n_samples, 0]\n",
    "\n",
    "df_test = np.array(test)\n",
    "df_test = df_test[:int(n_samples), :]\n",
    "\n",
    "x_test = df_test[:, 1:] / 255\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 28, 28))\n",
    "y_test = df_test[:, 0]\n",
    "\n",
    "#Convert sets to tensor\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_test = torch.from_numpy(y_test)\n",
    "\n",
    "print('Number of train samples: {}'.format(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_set = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "validation_set = torch.utils.data.TensorDataset(x_validation, y_validation)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2_drop): Dropout2d(p=0.25)\n",
       "  (fc1): Linear(in_features=320, out_features=120, bias=True)\n",
       "  (fc1_drop): Dropout(p=0.25)\n",
       "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #Convolution Layers\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d(p=0.25)\n",
    "        \n",
    "        #Linear layers\n",
    "        self.fc1 = nn.Linear(320, 120)\n",
    "        self.fc1_drop = nn.Dropout(p=0.25)\n",
    "        self.fc2 = nn.Linear(120, 10)\n",
    "    \n",
    "    def foward(self, x):\n",
    "        x = F.relu(F.max_pool2d(input=self.conv1(x), kernel_size=2))\n",
    "        x = F.relu(F.max_pool2d(input=self.conv2_drop(self.conv2(x)), kernel_size=2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1_drop(self.fc1(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x)\n",
    "                   \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        num_features = size.reduce(lambda x: num_features * x)\n",
    "        return num_features\n",
    "net = Net()\n",
    "net     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
